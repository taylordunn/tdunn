[
  {
    "path": "posts/2021-05-18-tidytuesday-week-21/",
    "title": "TidyTuesday Week 21",
    "description": "#TidyTuesday 2021-05-18: Ask a Manager Salary Survey",
    "author": [
      {
        "name": "Taylor Dunn",
        "url": {}
      }
    ],
    "date": "2021-05-18",
    "categories": [
      "tidytuesday"
    ],
    "contents": "\r\n\r\n\r\nknitr::opts_chunk$set(echo = TRUE)\r\nlibrary(tidyverse)\r\nlibrary(tidytuesdayR)\r\nlibrary(lubridate)\r\nlibrary(dunnr)\r\nextrafont::loadfonts(device = \"win\", quiet = TRUE)\r\ntheme_set(theme_td())\r\nset_geom_fonts()\r\nset_palette()\r\n\r\n\r\n\r\nLoad the data\r\n\r\n\r\ntt <- tt_load(\"2021-05-18\")\r\n\r\n\r\n\r\n    Downloading file 1 of 1: `survey.csv`\r\n\r\nThe data this week comes from the Ask a Manager Survey. From the README:\r\n\r\nThe salary survey a few weeks ago got a huge response — 24,000+ people shared their salaries and other info, which is a lot of raw data to sift through. Reader Elisabeth Engl kindly took the raw data and analyzed some of the trends in it and here’s what she found. (She asked me to note that she did this as a fun project to share some insights from the survey, rather than as a paid engagement.)\r\nThis data does not reflect the general population; it reflects Ask a Manager readers who self-selected to respond, which is a very different group (as you can see just from the demographic breakdown below, which is very white and very female).\r\n\r\nExplore the data\r\nIt comes with just the single dataframe:\r\n\r\n\r\nsurvey <- tt$survey\r\nglimpse(survey)\r\n\r\n\r\nRows: 26,232\r\nColumns: 18\r\n$ timestamp                                <chr> \"4/27/2021 11:02:10~\r\n$ how_old_are_you                          <chr> \"25-34\", \"25-34\", \"~\r\n$ industry                                 <chr> \"Education (Higher ~\r\n$ job_title                                <chr> \"Research and Instr~\r\n$ additional_context_on_job_title          <chr> NA, NA, NA, NA, NA,~\r\n$ annual_salary                            <dbl> 55000, 54600, 34000~\r\n$ other_monetary_comp                      <chr> \"0\", \"4000\", NA, \"3~\r\n$ currency                                 <chr> \"USD\", \"GBP\", \"USD\"~\r\n$ currency_other                           <chr> NA, NA, NA, NA, NA,~\r\n$ additional_context_on_income             <chr> NA, NA, NA, NA, NA,~\r\n$ country                                  <chr> \"United States\", \"U~\r\n$ state                                    <chr> \"Massachusetts\", NA~\r\n$ city                                     <chr> \"Boston\", \"Cambridg~\r\n$ overall_years_of_professional_experience <chr> \"5-7 years\", \"8 - 1~\r\n$ years_of_experience_in_field             <chr> \"5-7 years\", \"5-7 y~\r\n$ highest_level_of_education_completed     <chr> \"Master's degree\", ~\r\n$ gender                                   <chr> \"Woman\", \"Non-binar~\r\n$ race                                     <chr> \"White\", \"White\", \"~\r\n\r\nLooks like each row corresponds to a single survey. 26232 survey responses is really impressive. Here is how those were gathered over time:\r\n\r\n\r\n# Convert character timestamp to a datetime object so we can plot it\r\nsurvey <- survey %>%\r\n  mutate(\r\n    timestamp = lubridate::parse_date_time(timestamp, orders = \"mdy HMS\"),\r\n    survey_date = as.Date(timestamp)\r\n  )\r\nsurvey %>%\r\n  ggplot(aes(x = survey_date)) +\r\n  geom_bar(fill = td_colors$nice$day9_yellow, alpha = 0.6) +\r\n  scale_y_continuous(expand = expansion(c(0, 0.07))) +\r\n  scale_x_date(breaks = seq.Date(as.Date(\"2021-05-01\"),\r\n                                 as.Date(\"2021-06-01\"), by = \"week\"))\r\n\r\n\r\n\r\n\r\nOver 10,000 responses in one day!\r\nHere are the age ranges:\r\n\r\n\r\nsurvey %>%\r\n  count(how_old_are_you)\r\n\r\n\r\n# A tibble: 7 x 2\r\n  how_old_are_you     n\r\n  <chr>           <int>\r\n1 18-24            1015\r\n2 25-34           11748\r\n3 35-44            9398\r\n4 45-54            3042\r\n5 55-64             931\r\n6 65 or over         88\r\n7 under 18           10\r\n\r\nConvert to an ordered factor:\r\n\r\n\r\nsurvey <- survey %>%\r\n  mutate(\r\n    age_range = fct_reorder(\r\n      how_old_are_you,\r\n      # This will order the factor by the first number in how_old_are_you\r\n      parse_number(how_old_are_you)\r\n    ) %>%\r\n      fct_relevel(\"under 18\")\r\n  )\r\nsurvey %>%\r\n  ggplot(aes(y = age_range)) +\r\n  geom_bar(aes(fill = age_range), show.legend = FALSE) +\r\n  scale_fill_viridis_d() +\r\n  scale_x_continuous(expand = expansion(c(0, 0.05)))\r\n\r\n\r\n\r\n\r\nOut of curiosity, these are the 10 survey respondents listed as “under 18”:\r\n\r\n\r\nsurvey %>%\r\n  filter(age_range == \"under 18\") %>%\r\n  select(industry, job_title, annual_salary, country,\r\n         overall_years_of_professional_experience)\r\n\r\n\r\n# A tibble: 10 x 5\r\n   industry    job_title     annual_salary country overall_years_of_p~\r\n   <chr>       <chr>                 <dbl> <chr>   <chr>              \r\n 1 Education ~ Teacher               45000 USA     21 - 30 years      \r\n 2 Health care Undergraduat~         17000 United~ 2 - 4 years        \r\n 3 Retail      Walmart cash~         32552 Canada  2 - 4 years        \r\n 4 Health care Intern                29120 U.S.    2 - 4 years        \r\n 5 Nonprofits  Finance Dire~        118000 United~ 31 - 40 years      \r\n 6 Health care Doctor               220000 United~ 2 - 4 years        \r\n 7 Leisure, S~ Lifeguard, S~         34320 United~ 1 year or less     \r\n 8 Leisure, S~ Head Lifegau~         31200 United~ 2 - 4 years        \r\n 9 Law         Records mana~        106000 USA     41 years or more   \r\n10 Retail      Technology M~        100200 USA     21 - 30 years      \r\n\r\n  #gt()\r\n\r\n\r\n\r\nSome pretty impressive teenagers here. I think my favorite are the ones with more years of experience than years alive.\r\nAs for the industry variable, I know from checking out the survey itself that there are 26 options, +1 “Other” option to enter free-text. Do the most frequent 26 industry correspond to those preset options:\r\n\r\n\r\nsurvey %>%\r\n  count(industry, sort = T) %>%\r\n  head(30)\r\n\r\n\r\n# A tibble: 30 x 2\r\n   industry                                 n\r\n   <chr>                                <int>\r\n 1 Computing or Tech                     4360\r\n 2 Education (Higher Education)          2359\r\n 3 Nonprofits                            2331\r\n 4 Government and Public Administration  1821\r\n 5 Health care                           1739\r\n 6 Accounting, Banking & Finance         1688\r\n 7 Engineering or Manufacturing          1519\r\n 8 Marketing, Advertising & PR           1064\r\n 9 Law                                   1050\r\n10 Education (Primary/Secondary)          805\r\n# ... with 20 more rows\r\n\r\nNot quite, industry = “Publishing” is the 26th most frequent despite not being an option. Make a factor out of this variable, and group anything infrequent (<100 occurences) into “Other”:\r\n\r\n\r\nsurvey <- survey %>%\r\n  mutate(\r\n    industry_factor = fct_infreq(industry) %>%\r\n      fct_lump_min(min = 100)\r\n  )\r\nsurvey %>%\r\n  ggplot(aes(y = industry_factor)) +\r\n  geom_bar(fill = td_colors$nice$indigo_blue) +\r\n  scale_x_continuous(expand = c(0, 0))\r\n\r\n\r\n\r\n\r\nThe “Other” category accounts for a lot of responses.\r\nThe job_title variable is entirely free-text so will be difficult to use for any analysis/visualization, but here are the most common responses:\r\n\r\n\r\nsurvey %>%\r\n  count(job_title, sort = T)\r\n\r\n\r\n# A tibble: 12,622 x 2\r\n   job_title                    n\r\n   <chr>                    <int>\r\n 1 Software Engineer          289\r\n 2 Project Manager            242\r\n 3 Director                   211\r\n 4 Senior Software Engineer   200\r\n 5 Executive Assistant        171\r\n 6 Librarian                  160\r\n 7 Teacher                    160\r\n 8 Program Manager            152\r\n 9 Manager                    146\r\n10 Product Manager            122\r\n# ... with 12,612 more rows\r\n\r\nHow about job titles related to data or statistics or machine learning?\r\n\r\n\r\nsurvey %>%\r\n  filter(\r\n    str_detect(job_title,\r\n               regex(\"data|statistic|machine learn\", ignore_case = TRUE))\r\n  ) %>%\r\n  count(job_title, sort = T)\r\n\r\n\r\n# A tibble: 293 x 2\r\n   job_title                  n\r\n   <chr>                  <int>\r\n 1 Data Analyst              97\r\n 2 Data Scientist            60\r\n 3 Data analyst              25\r\n 4 Senior Data Scientist     21\r\n 5 Data Engineer             20\r\n 6 Data scientist            16\r\n 7 Senior Data Analyst       14\r\n 8 Data Manager              12\r\n 9 Database Administrator    12\r\n10 Statistician               9\r\n# ... with 283 more rows\r\n\r\nI might check this out later – quite a few responses.\r\nIn terms of location, we have country state, city, but I’ll just be looking at the country level for now:\r\n\r\n\r\nsurvey %>%\r\n  count(country, sort = T)\r\n\r\n\r\n# A tibble: 294 x 2\r\n   country                      n\r\n   <chr>                    <int>\r\n 1 United States             9010\r\n 2 USA                       7918\r\n 3 US                        2485\r\n 4 Canada                    1543\r\n 5 United Kingdom             584\r\n 6 UK                         579\r\n 7 U.S.                       569\r\n 8 United States of America   425\r\n 9 Usa                        420\r\n10 Australia                  368\r\n# ... with 284 more rows\r\n\r\nThis is in need of some data cleaning obviously. There are a lot of variations on “United States” that should be consolidated:\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-05-18-tidytuesday-week-21/tidytuesday-week-21-ask-a-manager-salary-survey_files/figure-html5/survey_timing-1.png",
    "last_modified": "2021-05-23T23:57:27-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-05-06-test-post/",
    "title": "test-post",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Taylor Dunn",
        "url": "https://twitter.com/TDunn12"
      }
    ],
    "date": "2021-05-06",
    "categories": [],
    "contents": "\r\nDistill is a publication format for scientific and technical writing, native to the web.\r\nLearn more about using Distill at https://rstudio.github.io/distill.\r\nHere is some example content.\r\n\r\n\r\nlibrary(dunnr)\r\nlibrary(ggplot2)\r\nlibrary(dplyr)\r\nlibrary(palmerpenguins)\r\nextrafont::loadfonts(device = \"win\", quiet = TRUE)\r\n\r\np1 <- penguins %>%\r\n  filter(!is.na(bill_length_mm)) %>%\r\n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +\r\n  geom_point(aes(shape = species), size = 3, alpha = 0.5, show.legend = FALSE) +\r\n  geom_smooth(method = \"lm\", formula = \"y ~ x\",\r\n              se = FALSE, show.legend = FALSE) +\r\n  labs(title = \"Penguin bill dimensions\",\r\n       subtitle = \"Bill length and depth for different penguin species\",\r\n       x = \"Bill length (mm)\", y = \"Bill depth (mm)\",\r\n       color = \"Penguin species\", shape = \"Penguin species\",\r\n       caption = \"Data from the palmerpenguins package.\") +\r\n  facet_wrap(~species, nrow = 1)\r\np1 + theme_td() + scale_color_td()\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-05-06-test-post/test-post_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-05-23T10:17:58-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to Taylor Dunn's personal website",
    "description": "Welcome to our new blog, Taylor Dunn's personal website. We hope you enjoy \nreading what we have to say!",
    "author": [
      {
        "name": "Nora Jones",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2021-05-06",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-05-23T10:17:58-04:00",
    "input_file": {}
  }
]
