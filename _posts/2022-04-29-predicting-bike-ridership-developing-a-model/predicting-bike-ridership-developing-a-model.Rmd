---
title: "Predicting bike ridership: developing a model"
description: |
  Part 2 of predicting bike ridership in Halifax, Nova Scotia. In this post,
  I explore and tune different modeling approaches.
author:
  - name: Taylor Dunn
date: 2022-04-29
params:
  date: 2022-04-29
  slug: 
categories:
  - R
  - machine learning
output:
  distill::distill_article:
    self_contained: false
    toc: true
draft: true
bibliography: references.bib
---

```{r setup, include=TRUE, code_folding="Setup"}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(gt)
library(patchwork)
library(tidymodels)

library(dunnr)
extrafont::loadfonts(device = "win", quiet = TRUE)
theme_set(theme_td())
set_geom_fonts()
set_palette()
```

## Introduction

Import the data from part 1:

```{r}
bike_ridership <- read_rds(
  "../2022-04-27-predicting-bike-ridership-getting-the-data/bike-ridership-data.rds"
)
```

## Exploratory data analysis

I've already done a bit of EDA in part 1, but I'll dive deeper in this post.

```{r}
glimpse(bike_ridership)
```

The `n_bikes` variable here is the total number of bikes counted at `site_name` over `count_date`.
In the original data, counts are recorded every hour which is reflected by the `n_records` variable:

```{r}
bike_ridership %>%
  count(site_name, n_records) %>%
  gt()
```

All except the Hollis St site have two channels (northbound and southbound), which is why `n_records` = 48. The entries with fewer `n_records` reflect the time of day that the data was extracted:

```{r}
bike_ridership %>%
  filter(n_records < 24) %>%
  select(site_name, count_date, n_records) %>%
  gt()
```

For this analysis, I will exclude this incomplete day:

```{r}
bike_ridership <- bike_ridership %>% filter(n_records > 8)
```

The date ranges for each site:

```{r fig.height=2, fig.width=5}
bike_ridership %>%
  group_by(site_name) %>%
  summarise(
    min_date = min(count_date), max_date = max(count_date),
    n_days = n(), .groups = "drop"
  ) %>%
  mutate(
    site_name = fct_reorder(site_name, min_date),
    n_days_label = ifelse(site_name == levels(site_name)[1],
                          str_c("n_days = ", n_days), n_days),
    midpoint_date = min_date + n_days / 2
  ) %>%
  ggplot(aes(y = site_name, color = site_name)) +
  geom_linerange(aes(xmin = min_date, xmax = max_date)) +
  geom_point(aes(x = min_date)) +
  geom_point(aes(x = max_date)) +
  geom_text(aes(label = n_days_label, x = midpoint_date), vjust = -0.5) +
  scale_y_discrete(labels = ~ str_wrap(., width = 15)) +
  labs(y = NULL, x = "min_date -> max_date") +
  theme(legend.position = "none")
```

For each site, the distribution of daily `n_bikes`:

```{r}
bike_ridership %>%
  ggplot(aes(x = n_bikes, fill = site_name)) +
  geom_histogram(bins = 30) +
  facet_wrap(~ str_trunc(site_name, 15)) +
  theme(legend.position = "none")
```

The South Park St site appears bimodal, which [I noted in part 1](../2022-04-27-predicting-bike-ridership-getting-the-data) was likely due to the addition of protected bike lanes in 2021.
This can be seen more clearly in the trend over time:

```{r fig.height=5, fig.width=6}
bike_ridership %>%
  ggplot(aes(x = count_date, y = n_bikes, color = site_name)) +
  geom_line() +
  facet_wrap(~ site_name, ncol = 1) +
  theme(legend.position = "none")
```

As you would expect for data in the same city, bike counters between sites are very highly correlated, which I can visualize:

```{r}
bike_ridership %>%
  transmute(count_date, n_bikes1 = n_bikes,
            site_name1 = factor(str_trunc(site_name, 10))) %>%
  left_join(., rename(., n_bikes2 = n_bikes1, site_name2 = site_name1),
            by = "count_date") %>%
  filter(as.numeric(site_name1) < as.numeric(site_name2)) %>%
  ggplot(aes(x = n_bikes1, y = n_bikes2)) +
  geom_point(aes(color = site_name1), alpha = 0.3) +
  facet_grid(site_name2 ~ site_name1) +
  theme(legend.position = "none") +
  dunnr::add_facet_borders()
```

The day of the week effect looks important:

```{r}
bike_ridership %>%
  mutate(day_of_week = lubridate::wday(count_date, label = TRUE)) %>%
  ggplot(aes(x = day_of_week, y = n_bikes)) +
  geom_jitter(aes(color = site_name), height = 0, width = 0.2, alpha = 0.3) +
  stat_summary(fun = "mean", geom = "point") +
  facet_wrap(~ site_name) +
  theme(legend.position = "none") +
  dunnr::add_facet_borders()
```

Another thing to consider is holidays.
I can get Canadian holidays with the `timeDate` package (which is how `recipes::step_holiday()` works):

```{r}
library(timeDate)
canada_holidays <-
  timeDate::listHolidays(
    pattern = "^CA|^Christmas|^NewYears|Easter[Sun|Mon]|^GoodFriday|^CaRem"
  )
canada_holidays
```

Then get the dates for each across the years in the bike data:

```{r}
canada_holiday_dates <- tibble(holiday = canada_holidays) %>%
  crossing(year = 2019:2022) %>%
  mutate(
    holiday_date = map2(
      year, holiday,
      ~ as.Date(timeDate::holiday(.x, .y)@Data)
    )
  ) %>%
  unnest(holiday_date)

canada_holiday_dates %>% rmarkdown::paged_table()
```

Only day I can think is missing from this list is Family Day (Heritage Day in Nova Scotia) which is the third Monday in February.
Visualize the effect of these holidays on bike ridership by plotting `n_bikes` in a 2 week window around the holidays (only the South Park St site for this plot):

```{r}
canada_holiday_dates %>%
  filter(holiday_date %in% unique(bike_ridership$count_date)) %>%
  mutate(
    date_window = map(holiday_date, ~ seq.Date(.x - 7, .x + 7, by = "1 day"))
  ) %>%
  unnest(date_window) %>%
  left_join(
    bike_ridership, by = c("date_window" = "count_date")
  ) %>%
  mutate(is_holiday = holiday_date == date_window) %>%
  group_by(holiday) %>%
  mutate(day_from_holiday = as.numeric(holiday_date - date_window)) %>%
  ungroup() %>%
  filter(site_name == "South Park St") %>%
  ggplot(aes(x = day_from_holiday, y = n_bikes,
             group = factor(year))) +
  geom_line() +
  geom_vline(xintercept = 0, lty = 2) +
  geom_point(aes(color = factor(year))) +
  scale_color_viridis_d("year") +
  facet_wrap(~ holiday) +
  dunnr::add_facet_borders() +
  theme(legend.position = "top")
```

The only holiday with a clear drop in ridership is Labour Day in 2021.
Victoria Day seems to have the opposite effect.
The Good Friday, Easter Sunday and Easter Monday holidays are obviously overlapping, and the `n_bikes` trend is a bit of a mess, but I can see an indication to the left of Good Friday that there may be a drop in ridership going into that weekend.

One thing to note is that the first, middle and last points correspond to the same day of the week, and the middle point in this set is usually lower than the other two, so holidays may be useful features in conjunction with day of the week.

The weather variables have varying levels of completeness:

```{r fig.height=2.5, fig.width=5}
# Separate out the weather data
weather_data <- bike_ridership %>%
  distinct(count_date, mean_temperature, total_precipitation,
           speed_max_gust, snow_on_ground)

weather_data %>%
  mutate(across(where(is.numeric), is.na)) %>%
  pivot_longer(cols = -count_date) %>%
  ggplot(aes(x = count_date, y = name)) +
  geom_tile(aes(fill = value)) +
  labs(y = NULL, x = NULL, fill = "Missing") +
  scale_fill_manual(values = c(td_colors$nice$indigo_blue, "gray80")) +
  scale_x_date(expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0)) +
  theme(legend.position = "top")
```

The distributions:

```{r fig.height=2.5, fig.width=6}
weather_data %>%
  pivot_longer(cols = -count_date) %>%
  filter(!is.na(value)) %>%
  ggplot(aes(x = value, fill = name)) +
  geom_histogram(bins = 30) +
  scale_y_continuous(expand = c(0, 0)) +
  facet_wrap(~ name, nrow = 1) +
  theme(legend.position = "none")
```

For non-missing cases, plot the pairwise relationships:

```{r}
weather_data %>%
  pivot_longer(cols = -count_date, names_to = "var1", values_to = "val1") %>%
  mutate(var1 = factor(var1)) %>%
  left_join(., rename(., var2 = var1, val2 = val1),
            by = "count_date") %>%
  filter(!is.na(val1), !is.na(val2),
         # Use numeric factor labels to remove duplicates
         as.numeric(var1) < as.numeric(var2)) %>%
  ggplot(aes(x = val1, y = val2, color = var1)) +
  geom_point(alpha = 0.5) +
  facet_grid(var2 ~ var1, scales = "free") +
  theme(legend.position = "none") +
  dunnr::add_facet_borders()
```

The clearest relationship to me is unsurprising: increasing `mean_temperature` is associated with decreasing `snow_on_ground` (top left plot).

Visualize relationships with `n_bikes`:

```{r}
bike_ridership %>%
  pivot_longer(
    cols = c(mean_temperature, total_precipitation,
             speed_max_gust, snow_on_ground),
    names_to = "var", values_to = "val"
  ) %>%
  filter(!is.na(val)) %>%
  ggplot(aes(x = val, y = n_bikes)) +
  geom_point(aes(color = str_trunc(site_name, 15)), alpha = 0.4) +
  facet_wrap(~ var, nrow = 2, scales = "free_x") +
  dunnr::add_facet_borders() +
  labs(x = NULL, color = NULL) +
  theme(legend.position = "bottom")
```

All of the weather variables seem to be associated with `n_bikes`.
In terms of predictive value, `mean_temperature` looks like it might be the most useful, and `speed_max_gust` the least.

## Feature engineering

From my EDA, I decided I want try including all 4 weather variables to predict bike ridership.
For some of the machine learning models I plan to try (like basic linear regression), this will require imputation of missing values, which I'll attempt here.

Add some more time variables for working with the `weather_data`:

```{r}
weather_data <- weather_data %>%
  mutate(count_year = lubridate::year(count_date),
         # Day number relative to earliest date
         count_day = as.numeric(count_date - min(count_date)),
         # Day of the year, from 1 to 365
         count_yday = lubridate::yday(count_date))
```

### Temperature

The `mean_temperature` variable is missing `r scales::percent(mean(is.na(weather_data$mean_temperature)))` of values.
Visualize the trend over time:

```{r}
p1 <- weather_data %>%
  filter(!is.na(mean_temperature)) %>%
  ggplot(aes(x = count_date, y = mean_temperature)) +
  geom_line(aes(color = factor(count_year))) +
  scale_color_viridis_d("year") +
  scale_x_date("date", date_breaks = "1 year")
p2 <- weather_data %>%
  filter(!is.na(mean_temperature)) %>%
  ggplot(aes(x = count_yday, y = mean_temperature)) +
  geom_line(aes(color = factor(count_year))) +
  scale_color_viridis_d("year") +
  scale_x_continuous("day of year", breaks = c(0, 90, 180, 270, 365)) +
  labs(y = NULL)
p1 + p2 +
  plot_layout(guides = "collect") &
  theme(legend.position = "top")
```

The cyclic nature makes it a good candidate for smoothing splines.
As a starting point, try a natural spline with 5 knots on the `count_yday` variable:

```{r}
library(splines)
lm_temperature <- 
  lm(mean_temperature ~ ns(count_yday, knots = 5),
      data = filter(weather_data, !is.na(mean_temperature)))

p1 +
  geom_line(
    data = augment(lm_temperature, newdata = weather_data),
    aes(y = .fitted), size = 1
  ) +
  theme(legend.position = "top")
```

We can obviously do a lot better.
I'll fit the data using a generalized additive model (GAM) with the `mgcv` package.^[Check out [this blog post by Gavin Simpson ](https://fromthebottomoftheheap.net/2014/05/09/modelling-seasonal-data-with-gam/) for a great walkthrough of modeling seasonal data with GAMs.]
For the `count_yday` variable (ranges from 1-365), I'll make sure that there is no discontinuity between year by using a *cyclic* spline (`bs = "cc"`).
I'll also include a smoothing term of `count_day` which will capture the trend across years.

```{r}
library(mgcv)

gam_temperature <-
  gam(mean_temperature ~ s(count_yday, bs = "cc", k = 12) + s(count_day),
      data = filter(weather_data, !is.na(mean_temperature)))
plot(gam_temperature, pages = 1, shade = TRUE)
```

The left plot shows the seasonal trend within a year (note the lines would connect at `count_yday` = 1 and 365), and the right plot shows the increase in average temperature throughout time (across years) after accounting for the seasonal effect.
Overlay the fit:

```{r}
p1 +
  geom_line(
    data = augment(gam_temperature, newdata = weather_data),
    aes(y = .fitted), size = 1
  ) +
  theme(legend.position = "top")
```

It doesn't capture some of the coldest temperatures, but I'm pretty happy with that.
I'll use predictions from the GAM model to impute missing days:

```{r}
bike_ridership <- bike_ridership %>%
  mutate(
    count_day = as.numeric(count_date - min(count_date)),
    count_yday = lubridate::yday(count_date),
  ) %>%
  bind_cols(pred = predict(gam_temperature, newdata = .)) %>%
  mutate(
    mean_temperature = ifelse(is.na(mean_temperature), pred,
                              mean_temperature)
  ) %>%
  select(-count_day, -count_yday, -pred)
```


### Precipitation and snow

The `total_precipitation` variable is missing
`r scales::percent(mean(is.na(weather_data$total_precipitation)))` of values;
`r scales::percent(mean(is.na(weather_data$snow_on_ground)))` for `snow_on_ground`.

The `total_precipitation` distribution:

```{r}
p1 <- weather_data %>%
  mutate(total_precipitation = replace_na(total_precipitation, -5)) %>%
  ggplot(aes(x = count_date, y = total_precipitation)) +
  geom_point(alpha = 0.5) +
  scale_y_continuous(breaks = c(-5, 0, 20, 40),
                     labels = c("missing", 0, 20, 40))
p1
```

This pattern of missing data during winter months makes me think that the `total_precipitation` is actually total rainfall, i.e. snowfall is not counted.
I'm going to impute the missing values with 0 during pre-processing, which is admittedly a poor approximation of the truth -- I know first-hand that there has been some rainy days in Halifax during April 2022, for example.

The `snow_on_ground` distribution:

```{r}
p2 <- weather_data %>%
  mutate(snow_on_ground = replace_na(snow_on_ground, -2)) %>%
  ggplot(aes(x = count_date, y = snow_on_ground)) +
  geom_point(alpha = 0.5) +
  scale_y_continuous(breaks = c(-2, 0, 10, 20),
                     labels = c("missing", 0, 10, 20))
p2
```

I'll also impute zero for missing `snow_on_ground`, which I'm a lot more confident doing here because most of the missing values occur during non-winter months.
A more careful approach might involve imputing 0 during non-winter months that I'm certain would have no snow on the ground, then modeling the winter months with something like a zero-inflated Poisson model.

### Wind speed

The `speed_max_gust` variable is the daily maximum wind speed in km/h, and has
`r scales::percent(mean(is.na(weather_data$speed_max_gust)))` missing values.

```{r}
mean_speed <- mean(weather_data$speed_max_gust, na.rm = TRUE)

weather_data %>%
  mutate(
    speed_max_gust = replace_na(speed_max_gust, 20)
  ) %>%
  ggplot(aes(x = count_date, y = speed_max_gust)) +
  geom_line(data = . %>% filter(speed_max_gust > 20)) +
  geom_smooth(data = . %>% filter(speed_max_gust > 20),
              method = "loess", formula = "y ~ x") +
  geom_hline(yintercept = mean_speed,
             color = td_colors$nice$opera_mauve, size = 1, lty = 2) +
  geom_jitter(data = . %>% filter(speed_max_gust == 20),
              width = 0, alpha = 0.5) +
  scale_y_continuous(breaks = c(mean_speed, 20, 40, 60, 80),
                     labels = c("mean_speed", "missing", 40, 60, 80))
```

Relative to the noise, the time trends are pretty minor, and the missing data looks to be missing at random.
I'll just impute using the mean speed.

### Lagged counts

As a time series data set, it would be careless to not account for past data when predicting future data.
One of the models I fit will be ARIMA, but for the other models I will include lagged `n_bikes` values.
Investigate the correlation in `n_bikes` for values lagged by 1, 2 and 3 days, and by 1 and 2 weeks (because they are the same day of the week):

```{r}
bike_ridership_lag <- bike_ridership %>%
  arrange(site_name, count_date) %>%
  group_by(site_name) %>%
  mutate(
    n_bikes_lag_1 = lag(n_bikes, 1),
    n_bikes_lag_2 = lag(n_bikes, 2),
    n_bikes_lag_3 = lag(n_bikes, 3),
    n_bikes_lag_7 = lag(n_bikes, 7),
    n_bikes_lag_14 = lag(n_bikes, 14)
  )
bike_ridership_lag %>%
  select(site_name, count_date, starts_with("n_bikes")) %>%
  pivot_longer(cols = matches("n_bikes_lag"),
               names_to = "lag_days", values_to = "n_bikes_lag") %>%
  filter(!is.na(n_bikes_lag)) %>%
  mutate(lag_days = str_extract(lag_days, "\\d+") %>% as.integer()) %>%
  group_by(site_name, lag_days) %>%
  mutate(corr_coef = cor(n_bikes, n_bikes_lag)) %>%
  ggplot(aes(x = n_bikes_lag, y = n_bikes, color = site_name)) +
  geom_point(alpha = 0.2) +
  geom_label(data = . %>% distinct(n_bikes_lag, site_name, corr_coef),
             aes(label = round(corr_coef, 2), x = 500, y = 200)) +
  geom_abline(slope = 1) +
  facet_grid(str_trunc(site_name, 10) ~ factor(lag_days)) +
  dunnr::add_facet_borders() +
  theme(legend.position = "none")
```

The 7- and 14-day lagged values are correlated just as strongly (in some cases stronger) than the other options.
This is great news because I only want to include a single lag variable, and using the 14th day lag means I can forecast 14 days ahead.

In order to use 14-day lag in a `tidymodels` workflow, I need to add it to the data myself.
The `step_lag()` function won't allow the outcome `n_bikes` to be lagged, because any new data won't have an `n_bikes` variable to use.
See [the warning in this section of the Tidy Modeling with R book](https://www.tmwr.org/recipes.html#skip-equals-true).
Add the `n_bikes_lag_14` predictor, and exclude any values without it:

```{r}
bike_ridership <- bike_ridership %>%
  group_by(site_name) %>%
  mutate(n_bikes_lag_14 = lag(n_bikes, 14)) %>%
  ungroup() %>%
  filter(!is.na(n_bikes_lag_14))
```

## Modeling

Register parallel computing:

```{r}
n_cores <- parallel::detectCores(logical = FALSE)
library(doParallel)
cl <- makePSOCKcluster(n_cores - 1)
registerDoParallel(cl)
# This extra step makes sure the parallel workers have access to the
#  `tidyr::replace_na()` function during pre-processing, which I use later on
# See this issue: https://github.com/tidymodels/tune/issues/364
parallel::clusterExport(cl, c("replace_na"))
```


### Splitting and resampling

For splitting the data into training and testing sets, there is the `initial_time_split()` function in `rsample` to account for the time dependence.

```{r fig.height=3}
# Need to order by time to properly use time split
bike_ridership <- bike_ridership %>% arrange(count_date, site_name)

set.seed(3005)
bike_split <- initial_time_split(bike_ridership, prop = 0.7)

bike_train <- training(bike_split)
bike_test <- testing(bike_split)

bind_rows(
  train = bike_train, test = bike_test, .id = "data_set"
) %>%
  group_by(data_set, site_name) %>%
  summarise(
    min_date = min(count_date), max_date = max(count_date),
    n_days = n(), midpoint_date = min_date + n_days / 2,
    .groups = "drop"
  ) %>%
  ggplot(aes(y = fct_reorder(site_name, min_date), color = data_set)) +
  geom_linerange(aes(xmin = min_date, xmax = max_date),
                 position = position_dodge(0.2)) +
  geom_point(aes(x = min_date), position = position_dodge(0.2)) +
  geom_point(aes(x = max_date), position = position_dodge(0.2)) +
  geom_text(aes(label = n_days, x = midpoint_date), vjust = -0.5,
            position = position_dodge(0.2), show.legend = FALSE) +
  labs(x = "date range", y = NULL, color = NULL)
```

It might make more sense to stratify by `site_name` so that there is a 70-30 split in each site.
^[Since `initial_time_split()` doesn't take `strata` argument, this would require defining a custom split function with `rsample::make_splits()`. This functionality might be available in future versions of `rsample` (see [this issue](https://github.com/tidymodels/rsample/issues/207)).]
For now, I'm using a simpler approach to split into the first 70% and 30% of the data.

For re-sampling, I will use `sliding_period()` to break up the data into 14 months of data (chosen to give 10 resamples) for analysis and 1 month for assessment:

```{r}
bike_resamples <-
  sliding_period(bike_train, index = count_date,
                 period = "month", lookback = 13, assess_stop = 1)
```

Visualize the resamples:

```{r}
bind_rows(
  analysis_set = map_dfr(bike_resamples$splits, analysis, .id = "i"),
  assessment_set = map_dfr(bike_resamples$splits, assessment, .id = "i"),
  .id = "data_set"
) %>%
  mutate(i = as.integer(i)) %>%
  group_by(i, data_set) %>%
  summarise(
    min_date = min(count_date), max_date = max(count_date),
    n_days = n(), midpoint_date = min_date + n_days / 2,
    .groups = "drop"
  ) %>%
  ggplot(aes(y = factor(i), color = data_set)) +
  geom_linerange(aes(xmin = min_date, xmax = max_date),
                 position = position_dodge(0.3)) +
  geom_point(aes(x = min_date), position = position_dodge(0.3)) +
  geom_point(aes(x = max_date), position = position_dodge(0.3)) +
  labs(x = "date range", y = NULL, color = NULL)
```

I'll define a set of metrics to use here as well:

```{r}
bike_metrics <- metric_set(rmse, rsq, mase, poisson_log_loss)
```

The Poisson log loss is a new one to me, that was [recently added to `yardstick`](https://yardstick.tidymodels.org/news/index.html#yardstick-0-0-9-2021-11-22).
I'll include it just for kicks, but I will choose my final model with `mase`, the mean absolute scaled error, which was introduced by Hyndman and Koehler [@Hyndman2006].
The MASE involves dividing the absolute forecast error ($|y_i - \hat{y}_i|$) by absolute *naive* forecast error (which involves forecasting with the last observed value).
The main advantage of this is that it is scale invariant.
Mean absolute percentage error (MAPE) is the typical scale-invariant choice in regression problems, but the MASE avoids dividing by `n_bikes` = 0 (of which there are some in this data set).
It also has a straightforward interpretation: values greater than one indicate a worse forecast than the naive method, and values less indicate better.

### Generalized linear models

```{r eval=FALSE}
bike_recipe_null <-
  recipe(n_bikes ~ n_bikes_lag_14, data = bike_train) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())
```

For my base model, I'll include just `site_name` and `n_bikes_lag_14`:

```{r}
bike_recipe <-
  recipe(n_bikes ~ count_date + site_name + n_bikes_lag_14,
         data = bike_train) %>%
  add_role(count_date, new_role = "date_variable") %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())
```

An extension of this model will include date variables.
I'll add day of week as categorical, day of year as numerical (and tune a natural spline function), year as numerical and Canadian holidays as caegorical.

```{r}
bike_recipe_date <-
  recipe(n_bikes ~ count_date + site_name + n_bikes_lag_14,
         data = bike_train) %>%
  add_role(count_date, new_role = "date_variable") %>%
  step_date(count_date, features = c("dow", "doy", "year"),
            label = TRUE, ordinal = FALSE) %>%
  step_ns(count_date_doy, deg_free = tune()) %>%
  step_holiday(count_date, holidays = canada_holidays) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())
```

I'll consider the weather variables (with some simple imputations) separately:

```{r}
bike_recipe_weather <-
  recipe(n_bikes ~ count_date + site_name + n_bikes_lag_14 + mean_temperature +
           total_precipitation + speed_max_gust + snow_on_ground,
         data = bike_train) %>%
  add_role(count_date, new_role = "date_variable") %>%
  step_impute_mean(speed_max_gust) %>%
  # Impute missing values with zero
  step_mutate_at(c(total_precipitation, snow_on_ground),
                 fn = ~ replace_na(., 0)) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())
```

And lastly, all the features:

```{r}
bike_recipe_date_weather <-
  recipe(n_bikes ~ count_date + site_name + n_bikes_lag_14 + mean_temperature +
           total_precipitation + speed_max_gust + snow_on_ground,
         data = bike_train) %>%
  add_role(count_date, new_role = "date_variable") %>%
  step_date(count_date, features = c("dow", "doy", "year"),
            label = TRUE, ordinal = FALSE) %>%
  step_ns(count_date_doy, deg_free = tune()) %>%
  step_holiday(count_date, holidays = canada_holidays) %>%
  step_impute_mean(speed_max_gust) %>%
  step_mutate_at(c(total_precipitation, snow_on_ground),
                 fn = ~ replace_na(., 0)) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())
```

The first models I will run these recipes through are simple linear regression and Poisson regression.
I would prefer to use negative binomial regression instead of Poisson to account for overdispersion (see aside), but [it hasn't been implemented in `parsnip` yet](https://github.com/tidymodels/parsnip/issues/35#issuecomment-1001088658).

<aside>

Over-dispersion in `n_bikes` (variance much higher than the mean):

```{r}
bike_ridership %>%
  group_by(site_name) %>%
  summarise(mean_n_bikes = mean(n_bikes), var_n_bikes = var(n_bikes)) %>%
  gt() %>%
  fmt_number(matches("n_bikes"), decimals = 1)
```

</aside>

```{r}
lm_spec <- linear_reg(engine = "lm")
library(poissonreg) # This wrapper package is required to use `poisson_reg()`
poisson_spec <- poisson_reg(engine = "glm")

wf_set_1 <- workflow_set(
  preproc = list(base = bike_recipe,
                 date = bike_recipe_date, weather = bike_recipe_weather,
                 date_weather = bike_recipe_date_weather),
  models = list(linear_reg = lm_spec, poisson_reg = poisson_spec),
  cross = TRUE
)
```

```{r}
wf_set_1_res <- workflow_map(
  wf_set_1,
  "tune_grid",
  # In this early stage, I'll try just a few `deg_free` in the spline term
  grid = grid_regular(deg_free(range = c(4, 7)), levels = 4),
  resamples = bike_resamples,
  metrics = bike_metrics, verbose = TRUE
)
```

For plotting the results of a set of workflows, I'll use a custom plotting function with `rank_results()`:

<aside>

I'm using my own function because the `workflowsets::autoplot()` function doesn't distinguish preprocessor recipes using the names provided to the `preproc` argument.
Below is an example (for just the RMSE metric):

```{r fig.height=4, fig.width=5}
autoplot(wf_set_1_res, metric = "rmse")
```

Note in the legend how all results have the "recipe" preprocessor, even though we have four different pre-processors: `bike_recipe`, `bike_recipe_date`, `bike_recipe_weather`, `bike_recipe_date_weather`.

</aside>

```{r}
plot_wf_set_metrics <- function(wf_set_res, rank_metric = "mase") {
  rank_results(wf_set_res, rank_metric = rank_metric) %>%
    mutate(preproc = str_remove(wflow_id, paste0("_", model))) %>%
    ggplot(aes(x = rank, y = mean, color = model, shape = preproc)) +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = mean - std_err, ymax = mean + std_err),
                  width = 0.2) +
    facet_wrap(~ .metric, scales = "free_y")
  
}
plot_wf_set_metrics(wf_set_1_res)
```

Across the board, the model will all the features (date and weather predictors; indicated by the square symbols) are best, and Poisson regression slightly outperforms linear.
Here are the models ranked by MASE:
^[Using the `select_best = TRUE` argument means only the best model in each workflow is returned. In this case, that means the workflows with the tunable spline feature of `count_date_doy` will only have one entry.]

```{r}
rank_results(wf_set_1_res, select_best = TRUE, rank_metric = "mase") %>%
  filter(.metric == "mase") %>%
  select(rank, wflow_id, .config, mean, std_err) %>%
  gt() %>%
  fmt_number(columns = c(mean, std_err), decimals = 3)
```

So our best workflow has the id `date_weather_poisson_reg` with the `.config` "Preprocessor2_Model1" which refers to a specific spline degree from our tuning of the `count_date_doy` feature.
Extract this workflow and checkout the results of the tuning:

```{r fig.height=4, fig.width=6}
bike_glm_workflow <-
  extract_workflow(wf_set_1_res, id = "date_weather_poisson_reg")
bike_glm_tune_res <-
  extract_workflow_set_result(wf_set_1_res, id = "date_weather_poisson_reg")
autoplot(bike_glm_tune_res)
```

The polynomial of degree 5 did best here.
Finalize the workflow and fit to the test data:

```{r}
bike_glm_workflow_best <-
  finalize_workflow(bike_glm_workflow,
                    select_best(bike_glm_tune_res, metric = "mase"))


bike_glm_fit <-
  last_fit(bike_glm_workflow_best, split = bike_split,
           metrics = bike_metrics)
```

The final metrics on the training and testing sets:

```{r}
bike_glm_metrics <- bike_glm_fit %>% collect_metrics()

bike_glm_workflow_final <- extract_workflow(bike_glm_fit)
bike_glm_metrics_train <- bike_glm_workflow_final %>%
  augment(bike_train) %>%
  bike_metrics(truth = n_bikes, estimate = .pred)

bind_rows(
  train = bike_glm_metrics_train,
  test = bike_glm_metrics,
  .id = "data_set"
) %>%
  select(.metric, data_set, .estimate) %>%
  pivot_wider(names_from = .metric, values_from = .estimate) %>%
  gt() %>%
  fmt_number(columns = -data_set, decimals = 2)
```

```{r}
bind_rows(
  train = augment(bike_glm_workflow_final, bike_train),
  test = augment(bike_glm_workflow_final, bike_test),
  .id = "data_set"
) %>%
  mutate(data_set = fct_inorder(data_set)) %>%
  ggplot(aes(x = count_date)) +
  geom_line(aes(y = n_bikes, color = site_name)) +
  geom_line(aes(y = .pred), color = "black") +
  facet_wrap(~ site_name, ncol = 1) +
  #facet_grid(site_name ~ data_set, scales = "free", shrink = TRUE) +
  theme(legend.position = "none")
```


```{r fig.height=7, fig.width=7}
library(performance)

bike_glm_fit$.workflow[[1]] %>%
  extract_fit_parsnip() %>%
  check_model()
```


```{r}
bike_glm_fit$.workflow[[1]] %>%
  extract_fit_engine() %>%
  check_overdispersion()
bike_glm_fit$.workflow[[1]] %>%
  extract_fit_engine() %>%
  check_heteroscedasticity()
```


```{r eval=FALSE}
xgboost_recipe <- 
  recipe(formula = n_bikes ~ site_name + n_bikes_lag_14, data = bike_train, clipboard = T) %>% 
  step_string2factor(one_of("site_name")) %>% 
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% 
  step_zv(all_predictors()) 

xgboost_spec <- 
  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), 
    loss_reduction = tune(), sample_size = tune()) %>% 
  set_mode("regression") %>% 
  set_engine("xgboost") 

xgboost_workflow <- 
  workflow() %>% 
  add_recipe(xgboost_recipe) %>% 
  add_model(xgboost_spec) 

set.seed(6376)
xgboost_tune <-
  tune_grid(xgboost_workflow, resamples = stop("add your rsample object"), grid = stop("add number of candidate points"))



usemodels::use_xgboost(n_bikes ~ site_name + n_bikes_lag_14, data = bike_train, clipboard = TRUE, colors = FALSE)
```


## Reproducibility {.appendix}

<details><summary>Session info</summary>

```{r echo=FALSE}
devtools::session_info()$platform
devtools::session_info()$packages %>%
  rmarkdown::paged_table()
```

</details>

<details><summary>Git repository</summary>

```{r echo=FALSE}
git2r::repository()
```

</details>

```{r echo=FALSE}
dunnr::get_distill_source(date = params$date, slug = params$slug)
```
